{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcbFlt0uJpNc"
      },
      "source": [
        "In this assignment you will be asked to extend the work by Gatti et al by checking whether form-meaning mappings learned on a different yet related language to that considered in the original study still capture the perceived valence of pseudowords. To do this you will be asked to engage with several different resources and adapt the pipeline following the instructions. Along the way, you will be asked to answer a few questions.\n",
        "\n",
        "You need to submit the complete notebook in .ipynb format, with intermediate outputs visible. The notebook should be named as follows:\n",
        "\n",
        "CL2025_groupN_assignment.ipynb\n",
        "\n",
        "where N is the group number. Submissions in the wrong format or with names not adhering to the guidelines will not be evaluated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OQbS5Urfit8W",
        "outputId": "2e59e6b8-77b1-40ca-9931-747a53b62329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'psycho-embeddings'...\n",
            "remote: Enumerating objects: 199, done.\u001b[K\n",
            "remote: Counting objects: 100% (199/199), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 199 (delta 105), reused 141 (delta 53), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (199/199), 67.91 KiB | 574.00 KiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n",
            "/content/psycho-embeddings\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313506 sha256=fda23ee6d2bdfbf5945d4cffd861be0ca5d0930127db99ae20aa3404c3799d07\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n",
            "Collecting pyreadr\n",
            "  Downloading pyreadr-0.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyreadr) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->pyreadr) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->pyreadr) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->pyreadr) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->pyreadr) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadr) (1.17.0)\n",
            "Downloading pyreadr-0.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.7/411.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyreadr\n",
            "Successfully installed pyreadr-0.5.3\n",
            "Collecting enchant\n",
            "  Downloading enchant-0.0.1-py3-none-any.whl.metadata (700 bytes)\n",
            "Downloading enchant-0.0.1-py3-none-any.whl (2.4 kB)\n",
            "Installing collected packages: enchant\n",
            "Successfully installed enchant-0.0.1\n",
            "Collecting pyenchant\n",
            "  Downloading pyenchant-3.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.2\n"
          ]
        }
      ],
      "source": [
        "# the code has been tested using the psycho-embeddings library to extract representations from LLMs.\n",
        "!git clone https://github.com/MilaNLProc/psycho-embeddings.git\n",
        "%cd psycho-embeddings\n",
        "!pip install datasets\n",
        "!pip install fasttext\n",
        "!pip install pyreadr\n",
        "!pip install enchant\n",
        "!pip install pyenchant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofb0L_c0AW0W",
        "outputId": "2efe8739-9a83-4ee5-d369-2226af60f15c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GroupViT models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version.Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "TAPAS models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version. Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n"
          ]
        }
      ],
      "source": [
        "# the solution to the assignment has been obtained using these packages.\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import fasttext as ft\n",
        "import pickle as pkl\n",
        "import fasttext.util\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from transformers import AutoTokenizer\n",
        "from psycho_embeddings import ContextualizedEmbedder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra3phcRhKuuo"
      },
      "source": [
        "**Task 1** (*10 points available, see breakdown per task below*)\n",
        "\n",
        "You should replicate the main design in the paper *Valence without meaning* by Gatti and colleagues (2024), using estimates collected for Dutch word valence to train linear regression models and apply them to predict the valence of English pseudowords from Gatti and colleagues.\n",
        "\n",
        "In detail, to train your regression models, you should use the dataset by Speed and Brysbaert (2024) containing crowd-sourced valence ratings (use the metadata to identify the relevant columns) collected for approximately 24,000 Dutch words. See the paper *Ratings of valence, arousal, happiness, anger, fear, sadness, disgust, and surprise for 24,000 Dutch words* by Speed and Brysbaert (2024).Use the dataset available at this link: https://osf.io/h76zj.\n",
        "\n",
        "You should train a letter unigram model and a bigram model. Each model should be trained on Dutch words only.\n",
        "\n",
        "Pay attention to one issue though: pseudowords created for English may be valid words in Dutch: therefore, you should first filter the list of pseudowords against a large store of Dutch words. To do so, use the words in the Dutch prevalence lexicon available in this OSF repository: https://osf.io/9zymw/. Essentially, you need to exclude any pseudoword that happens to be a word for which a prevalence estimate is available, whatever the prevalence is.\n",
        "\n",
        "Each code block indicates how many points are available and how they are attributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrHvq1OYEW6G"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Hrd4EhHlAcmi"
      },
      "outputs": [],
      "source": [
        "# read in the pseudowords from Gatti and colleagues, as well as the valence ratings for 24,000 Dutch words from Speed and Brysbaert (2024)\n",
        "# show the first 5 lines of each dataset.\n",
        "# 1 point for identifying the correct files and correctly loading their content\n",
        "\n",
        "import pyreadr\n",
        "import pandas as pd\n",
        "\n",
        "original = pyreadr.read_r('/content/data_pseudovalence.RData')\n",
        "dutch_lexicon = pd.read_csv('/content/prevalence_netherlands.csv', sep=\"\\t\")\n",
        "twentyfour_thousand= pd.read_excel('/content/SpeedBrysbaertEmotionNorms.xlsx')\n",
        "\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzA_oCuAKtyy",
        "outputId": "59ed1d87-0fd4-48ec-9c0a-f4577191ca21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      word  n.obs  irt.prevalence  z.irt.prevalence  prevalence  z.prevalence\n",
            "0  T-shirt    324        0.986622          2.215053    0.978395      1.689888\n",
            "1    aagje    303        0.907405          1.324941    0.877888      1.075808\n",
            "2     aagt    324        0.169817         -0.954888    0.188272     -0.827920\n",
            "3      aai    335        0.993290          2.472451    0.988060      1.794794\n",
            "4  aaibaar    333        0.996284          2.676802    0.990991      1.830889\n",
            "<bound method NDFrame.head of 0           T-shirt\n",
            "1             aagje\n",
            "2              aagt\n",
            "3               aai\n",
            "4           aaibaar\n",
            "            ...    \n",
            "54314           één\n",
            "54315    éénzijdige\n",
            "54316           öre\n",
            "54317     überhaupt\n",
            "54318    übermensch\n",
            "Name: word, Length: 54319, dtype: object>\n"
          ]
        }
      ],
      "source": [
        "print(dutch_lexicon.head())\n",
        "print(dutch_lexicon['word'].head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oo95C4HK0Hk",
        "outputId": "d4352cfe-484f-4005-b15e-9ae75b557d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Word   Arousal   Valence ValenceCategory ValenceVsNeutral  Happiness  \\\n",
            "0  mama  2.812500  4.000000        positive         valenced   3.300000   \n",
            "1    ja  2.823529  3.894737        positive         valenced   3.818182   \n",
            "2  papa  2.562500  3.722222        positive         valenced   4.142857   \n",
            "3   nee  2.928571  2.350000        negative          neutral   1.000000   \n",
            "4  kaka  3.357143  2.050000        negative          neutral   1.090909   \n",
            "\n",
            "      Anger      Fear   Sadness   Disgust  ...  Length Nsyl  N_phonemes  \\\n",
            "0  1.000000  1.000000  1.100000  1.000000  ...       4    2           4   \n",
            "1  1.090909  1.181818  1.181818  1.000000  ...       2    1           2   \n",
            "2  1.142857  1.000000  1.000000  1.000000  ...       4    2           4   \n",
            "3  1.727273  1.363636  1.454545  1.363636  ...       3    1           2   \n",
            "4  1.454545  1.181818  1.000000  4.727273  ...       4    2           4   \n",
            "\n",
            "        PoS  OLD20       AoA      DLP_RT   DLP_Acc   DCP_RT DCP_Acc  \n",
            "0         N   1.55  2.044257  513.530256  1.000000   931.03    0.99  \n",
            "1  Function   1.00  2.250000  494.980294  1.000000  1014.77    1.00  \n",
            "2         N   1.65  2.336327  570.497647  1.000000   936.88    0.99  \n",
            "3  Function   1.00  2.555556  488.637879  0.902439  1088.01    1.00  \n",
            "4         N   1.80  2.611111  629.402647  0.850000  1605.49    0.53  \n",
            "\n",
            "[5 rows x 35 columns]\n"
          ]
        }
      ],
      "source": [
        "print(twentyfour_thousand.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "4k7BDJdaLLIa",
        "outputId": "8ff971d1-b04a-4387-c581-56aebf872397"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"#loaded the words, with the [0], wrong collumn\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"X\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pseudoword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"abhict\",\n          \"acoed\",\n          \"acleat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06928813388248618,\n        \"min\": 0.434171333,\n        \"max\": 0.604888653,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.434171333,\n          0.538989524,\n          0.527803425\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.20700878087355,\n        \"min\": 5.552468433,\n        \"max\": 8.714640387,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8.233714393,\n          7.340002393,\n          5.552468433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predictedL_valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07595671864578904,\n        \"min\": 5.059183319,\n        \"max\": 5.262971027,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5.059183319,\n          5.115652307,\n          5.262971027\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predictedL_Bi_valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6743097748101607,\n        \"min\": 5.245825711,\n        \"max\": 6.562896274,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.509936083,\n          5.30972731,\n          5.245825711\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_Dim_valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9389666025035077,\n        \"min\": 5.268642829,\n        \"max\": 7.680826762,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7.366067564,\n          7.10566203,\n          5.268642829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predictedL_Dim_valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8656089304111382,\n        \"min\": 5.396114085,\n        \"max\": 7.58323032,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7.377534359,\n          7.024771169,\n          5.396114085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predictedBi_Dim_valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0242112358808242,\n        \"min\": 5.552468433,\n        \"max\": 8.233714393,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8.233714393,\n          7.340002393,\n          5.552468433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predictedBi_valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6353124951343498,\n        \"min\": 5.245825711,\n        \"max\": 6.509936083,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.509936083,\n          5.30972731,\n          5.245825711\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LDist\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ortho_VAL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1356693811627836,\n        \"min\": 3.09333333333333,\n        \"max\": 5.885,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.09333333333333,\n          5.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Semant_Neigh\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"cardigan\",\n          \"girl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SDist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04415026060936497,\n        \"min\": 0.499034622347403,\n        \"max\": 0.622202272576276,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.622202272576276,\n          0.499034622347403\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Semant_VAL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.465868343337832,\n        \"min\": 3.24,\n        \"max\": 7.15,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5.95,\n          7.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7025878b-25ae-4d0e-89e9-557a613b1a45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>pseudoword</th>\n",
              "      <th>Value</th>\n",
              "      <th>predicted_valence</th>\n",
              "      <th>predictedL_valence</th>\n",
              "      <th>predictedL_Bi_valence</th>\n",
              "      <th>predicted_Dim_valence</th>\n",
              "      <th>predictedL_Dim_valence</th>\n",
              "      <th>predictedBi_Dim_valence</th>\n",
              "      <th>predictedBi_valence</th>\n",
              "      <th>LDist</th>\n",
              "      <th>Ortho_VAL</th>\n",
              "      <th>Semant_Neigh</th>\n",
              "      <th>SDist</th>\n",
              "      <th>Semant_VAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>abhert</td>\n",
              "      <td>0.452501</td>\n",
              "      <td>7.414814</td>\n",
              "      <td>5.116167</td>\n",
              "      <td>6.444633</td>\n",
              "      <td>6.783771</td>\n",
              "      <td>6.630497</td>\n",
              "      <td>7.414814</td>\n",
              "      <td>6.444633</td>\n",
              "      <td>2</td>\n",
              "      <td>4.655714</td>\n",
              "      <td>ordinary</td>\n",
              "      <td>0.558492</td>\n",
              "      <td>5.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>abhict</td>\n",
              "      <td>0.434171</td>\n",
              "      <td>8.233714</td>\n",
              "      <td>5.059183</td>\n",
              "      <td>6.509936</td>\n",
              "      <td>7.366068</td>\n",
              "      <td>7.377534</td>\n",
              "      <td>8.233714</td>\n",
              "      <td>6.509936</td>\n",
              "      <td>2</td>\n",
              "      <td>3.093333</td>\n",
              "      <td>cardigan</td>\n",
              "      <td>0.622202</td>\n",
              "      <td>5.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>acleat</td>\n",
              "      <td>0.527803</td>\n",
              "      <td>5.552468</td>\n",
              "      <td>5.262971</td>\n",
              "      <td>5.245826</td>\n",
              "      <td>5.268643</td>\n",
              "      <td>5.396114</td>\n",
              "      <td>5.552468</td>\n",
              "      <td>5.245826</td>\n",
              "      <td>1</td>\n",
              "      <td>4.240000</td>\n",
              "      <td>solarium</td>\n",
              "      <td>0.575150</td>\n",
              "      <td>6.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>acmure</td>\n",
              "      <td>0.604889</td>\n",
              "      <td>8.714640</td>\n",
              "      <td>5.120029</td>\n",
              "      <td>6.562896</td>\n",
              "      <td>7.680827</td>\n",
              "      <td>7.583230</td>\n",
              "      <td>7.809910</td>\n",
              "      <td>5.414532</td>\n",
              "      <td>2</td>\n",
              "      <td>5.885000</td>\n",
              "      <td>bad</td>\n",
              "      <td>0.570299</td>\n",
              "      <td>3.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>acoed</td>\n",
              "      <td>0.538990</td>\n",
              "      <td>7.340002</td>\n",
              "      <td>5.115652</td>\n",
              "      <td>5.309727</td>\n",
              "      <td>7.105662</td>\n",
              "      <td>7.024771</td>\n",
              "      <td>7.340002</td>\n",
              "      <td>5.309727</td>\n",
              "      <td>1</td>\n",
              "      <td>5.680000</td>\n",
              "      <td>girl</td>\n",
              "      <td>0.499035</td>\n",
              "      <td>7.15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7025878b-25ae-4d0e-89e9-557a613b1a45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7025878b-25ae-4d0e-89e9-557a613b1a45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7025878b-25ae-4d0e-89e9-557a613b1a45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9ca204c9-5bda-48c5-a6c8-8d848f9d69a2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ca204c9-5bda-48c5-a6c8-8d848f9d69a2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9ca204c9-5bda-48c5-a6c8-8d848f9d69a2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   X pseudoword     Value  predicted_valence  predictedL_valence  \\\n",
              "0  1     abhert  0.452501           7.414814            5.116167   \n",
              "1  2     abhict  0.434171           8.233714            5.059183   \n",
              "2  3     acleat  0.527803           5.552468            5.262971   \n",
              "3  4     acmure  0.604889           8.714640            5.120029   \n",
              "4  5      acoed  0.538990           7.340002            5.115652   \n",
              "\n",
              "   predictedL_Bi_valence  predicted_Dim_valence  predictedL_Dim_valence  \\\n",
              "0               6.444633               6.783771                6.630497   \n",
              "1               6.509936               7.366068                7.377534   \n",
              "2               5.245826               5.268643                5.396114   \n",
              "3               6.562896               7.680827                7.583230   \n",
              "4               5.309727               7.105662                7.024771   \n",
              "\n",
              "   predictedBi_Dim_valence  predictedBi_valence  LDist  Ortho_VAL  \\\n",
              "0                 7.414814             6.444633      2   4.655714   \n",
              "1                 8.233714             6.509936      2   3.093333   \n",
              "2                 5.552468             5.245826      1   4.240000   \n",
              "3                 7.809910             5.414532      2   5.885000   \n",
              "4                 7.340002             5.309727      1   5.680000   \n",
              "\n",
              "  Semant_Neigh     SDist  Semant_VAL  \n",
              "0     ordinary  0.558492        5.05  \n",
              "1     cardigan  0.622202        5.95  \n",
              "2     solarium  0.575150        6.10  \n",
              "3          bad  0.570299        3.24  \n",
              "4         girl  0.499035        7.15  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pseudovalence_df = list(original.values())[1]\n",
        "pseudovalence_df.head()\n",
        "\n",
        "#loaded the words, with the [0], wrong collumn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rCUad_3FfKF",
        "outputId": "8012fa78-2b6b-4024-abd0-8c293a8809b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['data_fin', 'data_2', 'data_3', '.Random.seed', 'Count', 'comb_2', 'comb_3'])\n",
            "['abhert', 'abhict', 'acleat', 'acmure', 'acoed']\n",
            "next data:\n",
            "['acleat', 'acmure', 'acraw', 'adlor', 'adpite']\n",
            "   X pseudoword     Value  predicted_valence  predictedL_valence  \\\n",
            "0  1     abhert  0.452501           7.414814            5.116167   \n",
            "1  2     abhict  0.434171           8.233714            5.059183   \n",
            "2  3     acleat  0.527803           5.552468            5.262971   \n",
            "3  4     acmure  0.604889           8.714640            5.120029   \n",
            "4  5      acoed  0.538990           7.340002            5.115652   \n",
            "\n",
            "   predictedL_Bi_valence  predicted_Dim_valence  predictedL_Dim_valence  \\\n",
            "0               6.444633               6.783771                6.630497   \n",
            "1               6.509936               7.366068                7.377534   \n",
            "2               5.245826               5.268643                5.396114   \n",
            "3               6.562896               7.680827                7.583230   \n",
            "4               5.309727               7.105662                7.024771   \n",
            "\n",
            "   predictedBi_Dim_valence  predictedBi_valence  LDist  Ortho_VAL  \\\n",
            "0                 7.414814             6.444633      2   4.655714   \n",
            "1                 8.233714             6.509936      2   3.093333   \n",
            "2                 5.552468             5.245826      1   4.240000   \n",
            "3                 7.809910             5.414532      2   5.885000   \n",
            "4                 7.340002             5.309727      1   5.680000   \n",
            "\n",
            "  Semant_Neigh     SDist  Semant_VAL  \n",
            "0     ordinary  0.558492        5.05  \n",
            "1     cardigan  0.622202        5.95  \n",
            "2     solarium  0.575150        6.10  \n",
            "3          bad  0.570299        3.24  \n",
            "4         girl  0.499035        7.15  \n"
          ]
        }
      ],
      "source": [
        "print(original.keys())\n",
        "pseudowords0 = original['data_2']['pseudoword']\n",
        "pseudowords1 = original['data_3']['pseudoword']\n",
        "pseudowords0 = pseudowords0.tolist()\n",
        "pseudowords1 = pseudowords1.tolist()\n",
        "print(pseudowords0[:5])\n",
        "print('next data:')\n",
        "print(pseudowords1[:5])\n",
        "print(original['data_2'].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As4XV-LQPbyH",
        "outputId": "7d1f5eba-4456-4cf0-e19c-6ffe63c33783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "there are 54319 words in the lexicon\n",
            "pseudoword database length is 1500\n",
            "1499 are pseudowords\n",
            "and the words are ['abhert', 'abhict', 'acleat', 'acmure', 'acoed', 'acoy', 'acraw', 'adeb', 'adlor', 'adpite', 'adrord', 'aercup', 'aflo', 'aflouse', 'afruist', 'aftot', 'aftul', 'afuke', 'agind', 'akiype', 'akiyse', 'akiysm', 'alinch', 'alproubt', 'amesse', 'amle', 'ampgrair', 'ancil', 'anneenths', 'ansey', 'apeted', 'apgen', 'apgents', 'apgert', 'apgor', 'apgra', 'apjoled', 'apjorm', 'appite', 'apuss', 'areese', 'arepent', 'arfin', 'arreges', 'artaits', 'aruds', 'arvol', 'arwarts', 'asarps', 'ascel', 'atben', 'atelecks', 'atrur', 'atryr', 'atsty', 'attice', 'atux', 'avoed', 'avol', 'awgits', 'awslonts', 'awturps', 'axnur', 'axswan', 'axswe', 'axude', 'axwas', 'aymupt', 'baflew', 'balal', 'balrims', 'bancid', 'baper', 'bapet', 'bapey', 'bapger', 'bapgion', 'bapgy', 'bapil', 'barought', 'barrocts', 'basaves', 'bavelts', 'baxswing', 'bayfy', 'beenish', 'belorse', 'belsot', 'bengeer', 'beplalds', 'berroyed', 'betby', 'betrur', 'bewfet', 'bhubaxe', 'bhuxon', 'bicket', 'bigurs', 'bilming', 'binmi', 'bipar', 'bipgar', 'bipgead', 'bippen', 'blabful', 'blact', 'blandron', 'blasclumed', 'bleezes', 'blegjay', 'blelshed', 'blengely', 'bloffs', 'bluley', 'blussoths', 'bockoths', 'bollcole', 'bomden', 'bonfles', 'bonthome', 'booselons', 'boppies', 'boshons', 'boubty', 'bouscils', 'breafs', 'bripgred', 'brisps', 'brubing', 'buckthout', 'buido', 'bulpen', 'bunsal', 'bureer', 'bursing', 'butsling', 'buvners', 'byloin', 'byloms', 'caby', 'cackhage', 'calbiest', 'caldness', 'calow', 'calwathe', 'cameons', 'camid', 'campgree', 'caplime', 'carbeen', 'carounts', 'carvelays', 'casp', 'caub', 'cavral', 'caxnus', 'ceatrings', 'cecoat', 'cecs', 'cecur', 'cefflier', 'cegurs', 'celve', 'centy', 'cestop', 'chapefers', 'charb', 'chavot', 'cherses', 'chever', 'chezing', 'chiddy', 'chlorted', 'choleboard', 'chrine', 'chuessed', 'chufo', 'chulb', 'chulle', 'chund', 'churse', 'chussals', 'chuzzer', 'cibness', 'clace', 'clact', 'claky', 'clawbants', 'cleb', 'clebe', 'cleete', 'clesk', 'clesp', 'cley', 'clinfler', 'cloddener', 'cloor', 'coachgurbed', 'coaxnine', 'cobfic', 'cobnies', 'codhus', 'cofew', 'cofnun', 'cofrer', 'colboas', 'coldibed', 'collauce', 'colpust', 'combrince', 'compake', 'compesh', 'compracked', 'comwosed', 'conchyls', 'condeg', 'congesnes', 'congirds', 'conmince', 'connar', 'connusts', 'conshosts', 'coopan', 'copga', 'copger', 'copgies', 'copgred', 'copgy', 'copicts', 'corkner', 'corrift', 'corsoy', 'cothaw', 'couthstips', 'cowdled', 'coyryx', 'cpar', 'cracots', 'crair', 'cramney', 'crangles', 'cranser', 'cratching', 'crearking', 'creely', 'crewdly', 'creycound', 'crideles', 'cridgepeads', 'cridgers', 'cridths', 'crile', 'croal', 'crockack', 'cruker', 'cruns', 'crutto', 'cryps', 'culboaned', 'cundeans', 'cupgal', 'cutbroas', 'cybrane', 'cyclite', 'cymning', 'cyquanes', 'dackly', 'dagoul', 'dalf', 'dallead', 'dalp', 'danchunk', 'dapgel', 'dapger', 'dapging', 'daping', 'dardpour', 'dasarps', 'dasetail', 'dashup', 'debty', 'dededge', 'deedlosh', 'defoles', 'defotes', 'degaps', 'degide', 'dehosed', 'deplarked', 'depleare', 'deplews', 'depouts', 'deprods', 'deprumed', 'depuds', 'depursts', 'deshey', 'desombs', 'despast', 'desues', 'desurps', 'detilns', 'devash', 'dewshaps', 'dezien', 'dezil', 'dezins', 'deziss', 'dezist', 'dicicts', 'dideles', 'diferesce', 'diffrorn', 'digrechs', 'digrelf', 'dilthes', 'dilths', 'dilthy', 'dimbprong', 'dimians', 'dipgred', 'dipske', 'dipuns', 'direrbs', 'diruke', 'dirursts', 'dirurved', 'dischoyed', 'disdauched', 'disdettes', 'disdorn', 'disfroke', 'disgraked', 'disgraud', 'disgroose', 'dislack', 'dislaists', 'dislausts', 'dislolls', 'dispames', 'dispreged', 'disputs', 'disrusts', 'disspost', 'ditheless', 'divords', 'divucts', 'doelt', 'doep', 'dofis', 'donco', 'dondits', 'donfled', 'donfles', 'donpled', 'doolcrobs', 'dortness', 'doryls', 'drapgash', 'drockly', 'drumess', 'dullting', 'dumfrings', 'duntbews', 'dupung', 'dyish', 'dymph', 'ealm', 'eament', 'earsiews', 'eashwands', 'ecate', 'edil', 'edso', 'edsows', 'eemlid', 'efel', 'efem', 'efut', 'eilthetes', 'eintrus', 'ejoles', 'ekeme', 'elktess', 'ellachs', 'elptish', 'eltence', 'eltshia', 'elurb', 'emfess', 'emild', 'emperk', 'enscenged', 'envogs', 'envone', 'enzui', 'erar', 'erfig', 'erfy', 'erhess', 'erids', 'ermby', 'eroves', 'errords', 'erual', 'escharked', 'esfess', 'esjume', 'eslood', 'estherse', 'estism', 'etige', 'etirt', 'evede', 'ewaw', 'ewoche', 'exbrafes', 'exbrarb', 'exfanks', 'exfirt', 'exfis', 'exfo', 'exgise', 'exnal', 'exnouse', 'expia', 'extrurt', 'fabler', 'fafled', 'falm', 'faloor', 'famps', 'fandede', 'fanely', 'fangeer', 'fawis', 'feading', 'feartings', 'febs', 'febser', 'fedee', 'fedlones', 'feechings', 'feetbrates', 'feightel', 'felks', 'fempa', 'ferban', 'festags', 'fething', 'fibhin', 'fibire', 'fibsted', 'fidst', 'fiffy', 'filarm', 'fimigged', 'fivna', 'fixfeen', 'flackouns', 'flacmate', 'flandbons', 'flandron', 'flapgred', 'fleminned', 'flishen', 'fliy', 'floakly', 'floal', 'flofost', 'flooners', 'floovers', 'flowesh', 'fludging', 'flukdides', 'fluzz', 'foadeyes', 'foffrays', 'foluy', 'fordeats', 'forepape', 'forhol', 'forklypt', 'forual', 'fosed', 'fosels', 'fosetuls', 'foustered', 'fowntuls', 'fralode', 'frar', 'frarbed', 'frarm', 'frarthy', 'freapt', 'freardly', 'freazy', 'fubbar', 'fugcar', 'fukeer', 'funts', 'furgud', 'furnpiled', 'gafed', 'gagtres', 'galp', 'gansest', 'gapet', 'garples', 'garsons', 'gashbooms', 'gearl', 'ghactist', 'ghyps', 'gify', 'gign', 'gimskand', 'ginnies', 'girm', 'gisc', 'gisk', 'gixgaws', 'glanny', 'glelve', 'glirehouse', 'gloaks', 'gnopi', 'gnort', 'gnud', 'goep', 'gomben', 'gomsat', 'goontier', 'gouilhalls', 'grager', 'grelles', 'grempes', 'grendness', 'gricking', 'grinva', 'groanfuls', 'groilstone', 'groosted', 'gropness', 'groultes', 'guddre', 'gurb', 'guyber', 'gypgrip', 'gypgup', 'habbled', 'hact', 'hastuck', 'haxli', 'hedly', 'hicies', 'hictades', 'hijoned', 'hildby', 'hirries', 'hiser', 'hodgier', 'hoeser', 'holchoun', 'homlead', 'homptes', 'honch', 'hoober', 'horfy', 'hortuds', 'hosetuls', 'houthwills', 'howlpifts', 'hownab', 'hufa', 'hufo', 'hufy', 'hugey', 'hukes', 'humpiers', 'hutby', 'hutip', 'hygcup', 'iass', 'ifry', 'igla', 'igly', 'ikieth', 'illweme', 'imblock', 'imblodes', 'imbloles', 'imbott', 'imboves', 'imbropts', 'imbting', 'imbuled', 'imbyne', 'immepped', 'impails', 'inchained', 'incyps', 'infeard', 'infeart', 'infeme', 'ingills', 'injaps', 'inmead', 'inquact', 'insimes', 'inswols', 'invets', 'invont', 'irits', 'isax', 'ivosh', 'jaloor', 'japet', 'japgine', 'jarb', 'jasp', 'jawk', 'jayunct', 'jecrides', 'jelms', 'jerdint', 'jerlous', 'jessuls', 'jilths', 'jipping', 'jirm', 'jitting', 'jodd', 'jodry', 'jogy', 'jomeers', 'jomsaw', 'jonfles', 'jonier', 'josk', 'jouse', 'joygade', 'jumbty', 'jupsers', 'jurn', 'kangling', 'kankmen', 'kedges', 'kepgote', 'ketkin', 'keve', 'khars', 'kibid', 'kittings', 'kivs', 'knackets', 'knibe', 'kniln', 'knilques', 'knimly', 'knist', 'kockals', 'krennix', 'kritched', 'kuldies', 'kusgrels', 'labtered', 'lagobe', 'lalal', 'lalktost', 'lambeen', 'lanja', 'larwan', 'laryl', 'lault', 'laxfel', 'leabup', 'leboss', 'lebost', 'leging', 'lelk', 'lestest', 'levrees', 'liflo', 'lilgite', 'lindedes', 'lintres', 'lipgre', 'lipgus', 'liptie', 'lirlest', 'lisy', 'litple', 'lixics', 'lixthless', 'locin', 'loduy', 'loindroin', 'lokier', 'lomosts', 'lootmork', 'lopber', 'lopgo', 'lorsor', 'losiave', 'losish', 'loubts', 'lubo', 'lunchlill', 'lurb', 'luys', 'lylik', 'lyll', 'mabfie', 'mabhew', 'mabhey', 'mabio', 'macnyl', 'maddage', 'maifs', 'maistes', 'mambs', 'mamled', 'mampen', 'mancmer', 'mannours', 'mapge', 'mapger', 'masp', 'matben', 'mavel', 'meaf', 'mebyl', 'meetier', 'meywas', 'midsteps', 'miek', 'miet', 'migrechs', 'migremns', 'milmeged', 'milys', 'mineg', 'minnip', 'mirdbop', 'misdalds', 'misdarms', 'misdels', 'miseau', 'miskips', 'misnels', 'misnil', 'misnive', 'misnyps', 'mispleged', 'misplirds', 'misprolls', 'misqualt', 'misquirds', 'misslites', 'missols', 'mistrecks', 'mixea', 'mobort', 'mocys', 'moglede', 'mointents', 'moitis', 'molltents', 'mombfure', 'monpleants', 'monsmal', 'montein', 'mooge', 'mopial', 'morkfure', 'mosicised', 'moung', 'moungern', 'mouno', 'mousaw', 'moyca', 'muester', 'mujok', 'mundats', 'muplids', 'mutolls', 'mutsles', 'mype', 'myrry', 'myvet', 'naaclon', 'nabat', 'nact', 'nacty', 'namb', 'namters', 'naoade', 'narrause', 'naslepans', 'navol', 'nedukes', 'nermast', 'nertal', 'niaps', 'nibe', 'nilthe', 'niltres', 'nimdad', 'nipgred', 'nirthquess', 'nivny', 'nixny', 'nodills', 'noep', 'nokists', 'nokly', 'nokra', 'nollpins', 'nolve', 'noopness', 'norttag', 'nospese', 'notbed', 'nouble', 'noup', 'novra', 'noxfees', 'nuct', 'nugcouse', 'nuisills', 'nunk', 'nupleil', 'nurdres', 'nusgrell', 'nutbrill', 'nutgres', 'nyps', 'oamless', 'obsledes', 'ocised', 'ojosh', 'onbund', 'onfless', 'onots', 'onstrang', 'onup', 'opgeans', 'osner', 'otstruke', 'ottruds', 'oubnest', 'oukol', 'ounza', 'ovaft', 'pacous', 'pafi', 'palpes', 'pambfip', 'pamet', 'paobe', 'parb', 'parmly', 'parseak', 'parthbex', 'paselem', 'pathly', 'patmy', 'patpard', 'paughels', 'paythy', 'peasetice', 'pebgred', 'pebgring', 'pebi', 'pecle', 'pecly', 'pectoun', 'pedtail', 'pegen', 'pegie', 'pegoa', 'peisels', 'pemy', 'penarn', 'penching', 'pentirs', 'peok', 'pepioes', 'petly', 'pewbin', 'pewn', 'pewt', 'phame', 'phigging', 'phrace', 'phratted', 'phyheak', 'piedy', 'pilked', 'pipid', 'piteer', 'plailtinch', 'plarched', 'plawen', 'plazzed', 'plictrups', 'pliming', 'plinches', 'plirled', 'plording', 'plotsy', 'ploused', 'plussard', 'plyglyss', 'plynching', 'plyten', 'poarsy', 'poblets', 'pockatz', 'pofflat', 'polif', 'ponatch', 'ponawls', 'ponfla', 'popend', 'popese', 'popging', 'postord', 'potko', 'potmers', 'pounts', 'povels', 'povers', 'poves', 'povya', 'powzed', 'poyings', 'pradging', 'pralse', 'pramboos', 'prean', 'prearking', 'prebupt', 'precoys', 'preemful', 'preepy', 'prefting', 'premiege', 'premp', 'prepond', 'prerchy', 'prib', 'prily', 'prirt', 'procians', 'prockack', 'prockils', 'propeaned', 'prummered', 'pruncils', 'pseuding', 'pubrel', 'pulates', 'punsies', 'punstack', 'puntol', 'pupgar', 'purbits', 'purfuced', 'pusthin', 'puychers', 'puyfred', 'pycran', 'pydin', 'pyniack', 'pyniale', 'pyniard', 'pynprus', 'pynskus', 'pysby', 'quimners', 'radret', 'ragtif', 'ralein', 'ralp', 'rampnit', 'ranooned', 'ransede', 'rapwring', 'rarb', 'rareme', 'rargo', 'rattels', 'ratux', 'rauds', 'rayor', 'realan', 'rebio', 'rebrites', 'reclomb', 'redrel', 'reduls', 'refamb', 'reglief', 'rejawed', 'relocts', 'renute', 'repcor', 'repebs', 'repove', 'rerake', 'resapse', 'restood', 'restruke', 'resule', 'revrete', 'rewbor', 'rewik', 'rhizave', 'ribnier', 'riegles', 'rirnian', 'roachup', 'roafen', 'rolas', 'roosstep', 'ropger', 'ropgred', 'rorl', 'rorsts', 'rotger', 'rubnies', 'ruckgroof', 'rumbness', 'runcils', 'rurb', 'ruscet', 'ruxgle', 'sabued', 'sabuged', 'sabuy', 'sackthoks', 'sakply', 'saky', 'salcees', 'salgy', 'sallspoid', 'samry', 'samuy', 'sarian', 'sarmly', 'sarmo', 'sarmy', 'sarty', 'satbe', 'satly', 'sayors', 'scantawls', 'sceggres', 'scere', 'scerny', 'schoying', 'sciller', 'scispre', 'scrule', 'scruped', 'sculps', 'seave', 'secruds', 'sedsom', 'sedtaps', 'sefen', 'segrance', 'seniule', 'septen', 'sevu', 'sewel', 'shalders', 'shalicts', 'shalid', 'shaulty', 'shedels', 'sheights', 'shickyand', 'shipgruck', 'shirm', 'shockils', 'shonchos', 'shooply', 'shopial', 'shorgers', 'shorgled', 'showl', 'showzest', 'shremmer', 'shubdoids', 'shubdoint', 'shustier', 'sibit', 'sibre', 'sifed', 'silths', 'sipad', 'sipal', 'sipot', 'siseals', 'sivicine', 'skaxness', 'skeb', 'skeded', 'skibfy', 'skiyr', 'slairles', 'slakh', 'slearting', 'slifting', 'slod', 'slonients', 'sloursless', 'slouways', 'sloying', 'sludgers', 'sluses', 'smaggered', 'smamps', 'smapsick', 'smeasasts', 'smerding', 'smocy', 'smustcap', 'snabbled', 'snallox', 'snidness', 'snools', 'snukebise', 'sobmered', 'sobsiers', 'sodet', 'soduat', 'soglings', 'soniel', 'sonples', 'sonx', 'sopger', 'sorquom', 'sorrips', 'sowesh', 'sowly', 'spackmalk', 'spanscer', 'spapscing', 'spearn', 'speathlier', 'spechy', 'spever', 'spevs', 'spibfy', 'spiekes', 'spillstones', 'splanium', 'splil', 'spombful', 'spowen', 'spoying', 'spreated', 'sprilt', 'sprinkays', 'squazzing', 'squerding', 'squeshotte', 'stangcays', 'stashgys', 'stazz', 'stearvast', 'stedbled', 'sterty', 'stonzed', 'stosead', 'stralser', 'stramy', 'strardles', 'straughtecks', 'strautchexed', 'streller', 'strukes', 'strur', 'sturorm', 'stutpons', 'stybee', 'styvos', 'succempts', 'sugcay', 'sugjucts', 'sulfit', 'sumbest', 'sunweem', 'supgry', 'supmeons', 'suppald', 'surfoths', 'sursawed', 'sustium', 'suswects', 'suyural', 'swact', 'swarting', 'swazzing', 'swilths', 'swimacks', 'swirps', 'swisfy', 'switchcraps', 'swolls', 'swund', 'sybfians', 'tadtens', 'taftly', 'tambtul', 'tamstreng', 'tarchless', 'tardled', 'tarving', 'tarvos', 'tarvul', 'tarwis', 'tarxest', 'tarxi', 'tasp', 'tatchhey', 'tathpoy', 'tattenipts', 'tattoubt', 'taxpors', 'teansing', 'teccy', 'tecterts', 'teded', 'teguths', 'telfure', 'tencmics', 'tepral', 'termoth', 'tersless', 'texlirt', 'teyin', 'teziels', 'thaca', 'thiels', 'thobbling', 'thosh', 'thoving', 'threet', 'threthes', 'thriper', 'thronk', 'throseless', 'thrun', 'thupe', 'thwain', 'thwarns', 'tiake', 'tibfy', 'tievage', 'timloe', 'tipgred', 'tirks', 'tobfost', 'toeban', 'toep', 'tolque', 'toubt', 'toutured', 'towtion', 'trachms', 'traffiths', 'trapgeer', 'trapgior', 'trarb', 'trardlers', 'trareplacks', 'tratecate', 'trearkers', 'trefewn', 'trenchexed', 'trexpossed', 'tridging', 'trissling', 'triyrs', 'trobbles', 'troolblip', 'troolstips', 'trufts', 'trukels', 'trukers', 'trukes', 'trukhing', 'trumbs', 'trynger', 'tudmies', 'tulpt', 'tulthum', 'tunged', 'tunsuls', 'tupgred', 'turpled', 'tusler', 'tuwhe', 'tuxgers', 'twertle', 'twilm', 'twingre', 'twique', 'tybeens', 'uards', 'uatz', 'ubint', 'ubnil', 'ubty', 'ubwand', 'uccurb', 'udstame', 'ughoyed', 'uglong', 'ulsping', 'ultule', 'uncemned', 'unces', 'uncien', 'uncing', 'uneits', 'unfism', 'unfith', 'unjits', 'unkiffs', 'unpoils', 'unstyps', 'unwhissed', 'unwips', 'unwoomed', 'upga', 'upgeer', 'upgion', 'upgoup', 'upua', 'ureo', 'urglon', 'urki', 'urpet', 'usce', 'uslard', 'usler', 'uwies', 'vagolve', 'valf', 'valp', 'vares', 'vebe', 'velead', 'velull', 'vergact', 'verkans', 'vevem', 'vibcines', 'vifan', 'viker', 'villup', 'vimby', 'vime', 'visk', 'viute', 'vivrerred', 'vixgle', 'volleed', 'volols', 'votaws', 'votko', 'voulnals', 'vounly', 'vubfar', 'vubnar', 'vufas', 'vuftie', 'vugloi', 'vussals', 'vussuls', 'wabtaffs', 'wabtave', 'wabwand', 'waca', 'wapgred', 'warb', 'wareies', 'warker', 'wassown', 'wava', 'wawened', 'wayfle', 'wazo', 'wearn', 'webtless', 'weecly', 'weef', 'weenman', 'weifnight', 'welup', 'werb', 'werble', 'werfy', 'werier', 'werm', 'whak', 'wheam', 'whez', 'whickstap', 'whily', 'whisspeals', 'whisspouls', 'whombers', 'whosouts', 'whosting', 'whowzage', 'wikh', 'wiky', 'willup', 'wilths', 'wimelat', 'wirps', 'wisdening', 'wizer', 'wodgal', 'woller', 'woost', 'wootworn', 'worglers', 'woshbop', 'wothing', 'wreague', 'wroltres', 'wubes', 'xecoc', 'xecos', 'xedan', 'xeddish', 'xedi', 'xedin', 'xedo', 'xefla', 'xegan', 'xegman', 'xegna', 'xeken', 'xeli', 'xelman', 'xelo', 'xembies', 'xemi', 'xemin', 'xemix', 'xemmians', 'xengtho', 'xeotan', 'xepo', 'xepra', 'xepu', 'xequa', 'xeras', 'xesca', 'xesex', 'xesma', 'xesok', 'xesos', 'xetob', 'xetof', 'xetog', 'xetos', 'xetow', 'xetten', 'xetty', 'xexen', 'xmat', 'yabe', 'yary', 'yishing', 'yofi', 'youncing', 'yual', 'yunal', 'yupen', 'yuppea', 'yury', 'yusi', 'yuxwas', 'yuywas', 'zauze', 'zerow', 'zilk', 'zohels', 'zokils']\n",
            "there are 1 dutch words\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['pimpen']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# filter out pseudowords that happen to be valid Dutch words (mind case folding!)\n",
        "# show the set of pseudowords filtered out.\n",
        "# 1 point for applying the correct filtering\n",
        "\n",
        "# for each pseudoword it is checked if it is part of the Dutch prevalence lexicon, if this is the case it is considered as a dutch word.\n",
        "# with the only dutch word being found: pimpen.\n",
        "\n",
        "dutch_words=[]\n",
        "pseudoword_complete= []\n",
        "\n",
        "dutch_lexicon_lower = []\n",
        "for ele in dutch_lexicon[\"word\"]:\n",
        "  dutch_lexicon_lower.append(ele.lower())\n",
        "\n",
        "for i in pseudowords0:\n",
        "  if i not in dutch_lexicon_lower:\n",
        "    pseudoword_complete.append(i)\n",
        "  else:\n",
        "    dutch_words.append(i)\n",
        "\n",
        "print(\"there are\",len(dutch_lexicon_lower), \"words in the lexicon\")\n",
        "print(\"pseudoword database length is\", len(pseudowords0))\n",
        "print(len(pseudoword_complete), \"are pseudowords\")\n",
        "print(\"and the words are\", pseudoword_complete)\n",
        "print(\"there are\",len(dutch_words), \"dutch words\")\n",
        "dutch_words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_6b-4q4h_vi",
        "outputId": "5df1ca4f-fd57-4791-cc07-68c73fb7e0d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1500\n",
            "900\n",
            "1499\n"
          ]
        }
      ],
      "source": [
        "true_valence_pseudo_word = original['data_2']['predicted_valence']\n",
        "print(len(true_valence_pseudo_word))\n",
        "print(pseudowords0.index('pimpen'))\n",
        "del true_valence_pseudo_word[900]\n",
        "print(len(true_valence_pseudo_word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvza9pb6MFgC"
      },
      "outputs": [],
      "source": [
        "# encode Dutch words and pseudowords from Gatti et al as uni- and bi-gram vectors\n",
        "# show the uni-gram and bi-gram encoding of the pseudoword ampgrair\n",
        "# 2 points for correctly encoding the target strings as uni- and bi-gram vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjJBMKije_ZZ",
        "outputId": "b71af3a6-8fcb-42b5-831e-5eab5e6970ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique unigrams: 34\n",
            "Unigrams: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ö', 'ü']\n",
            "\n",
            "Number of unique bigrams: 656\n",
            "Sample bigrams: ['#a', '#b', '#c', '#d', '#e', '#f', '#g', '#h', '#i', '#j']...\n",
            "\n",
            "\n",
            "Encoding for 'ampgrair':\n",
            "Uni-gram vector shape: (34,)\n",
            "Uni-gram encoding: [2. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Bi-gram vector shape: (656,)\n",
            "Bi-gram encoding: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Active unigrams in 'ampgrair':\n",
            "  'a': 2 times\n",
            "  'g': 1 times\n",
            "  'i': 1 times\n",
            "  'm': 1 times\n",
            "  'p': 1 times\n",
            "  'r': 2 times\n",
            "\n",
            "Active bigrams in 'ampgrair' (with boundaries):\n",
            "  '#a': 1 times\n",
            "  'ai': 1 times\n",
            "  'am': 1 times\n",
            "  'gr': 1 times\n",
            "  'ir': 1 times\n",
            "  'mp': 1 times\n",
            "  'pg': 1 times\n",
            "  'r#': 1 times\n",
            "  'ra': 1 times\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def extract_ngram_features(training_words):\n",
        "    \"\"\"Extract unique uni-grams and bi-grams from training data\"\"\"\n",
        "    unigrams = set()\n",
        "    bigrams = set()\n",
        "\n",
        "    for word in training_words:\n",
        "        word_str = str(word)\n",
        "        # Add word boundary markers\n",
        "        word_with_boundaries = '#' + word_str + '#'\n",
        "\n",
        "        # Extract unigrams\n",
        "        for char in word_str:\n",
        "            unigrams.add(char)\n",
        "\n",
        "        # Extract bigrams\n",
        "        for i in range(len(word_with_boundaries) - 1):\n",
        "            bigram = word_with_boundaries[i:i+2]\n",
        "            bigrams.add(bigram)\n",
        "\n",
        "    unigram_list = sorted(list(unigrams))\n",
        "    bigram_list = sorted(list(bigrams))\n",
        "\n",
        "    return unigram_list, bigram_list\n",
        "\n",
        "def encode_ngrams(word, unigram_features, bigram_features):\n",
        "    \"\"\"Encode a word using the extracted n-gram features\"\"\"\n",
        "    # Create feature vectors\n",
        "    uni_vector = np.zeros(len(unigram_features))\n",
        "    bi_vector = np.zeros(len(bigram_features))\n",
        "    word_str = str(word)\n",
        "\n",
        "    # Unigram encoding\n",
        "    for char in word_str:\n",
        "        if char in unigram_features:\n",
        "            idx = unigram_features.index(char)\n",
        "            uni_vector[idx] += 1\n",
        "\n",
        "    # Bigram encoding with word boundaries\n",
        "    word_with_boundaries = '#' + word_str + '#'\n",
        "    for i in range(len(word_with_boundaries) - 1):\n",
        "        bigram = word_with_boundaries[i:i+2]\n",
        "        if bigram in bigram_features:\n",
        "            idx = bigram_features.index(bigram)\n",
        "            bi_vector[idx] += 1\n",
        "\n",
        "    return uni_vector, bi_vector\n",
        "\n",
        "# The training data is the list of Dutch words from Speed and Brysbaert\n",
        "training_data = twentyfour_thousand['Word'].tolist()\n",
        "\n",
        "# Extract features from training data\n",
        "unigram_features, bigram_features = extract_ngram_features(training_data)\n",
        "\n",
        "print(f\"Number of unique unigrams: {len(unigram_features)}\")\n",
        "print(f\"Unigrams: {unigram_features}\")\n",
        "print(f\"\\nNumber of unique bigrams: {len(bigram_features)}\")\n",
        "print(f\"Sample bigrams: {bigram_features[:10]}...\")\n",
        "\n",
        "# Encode the pseudoword \"ampgrair\"\n",
        "target_word = \"ampgrair\"\n",
        "uni_result, bi_result = encode_ngrams(target_word, unigram_features, bigram_features)\n",
        "\n",
        "print(f\"\\n\\nEncoding for '{target_word}':\")\n",
        "print(f\"Uni-gram vector shape: {uni_result.shape}\")\n",
        "print(f\"Uni-gram encoding: {uni_result}\")\n",
        "\n",
        "print(f\"\\nBi-gram vector shape: {bi_result.shape}\")\n",
        "print(f\"Bi-gram encoding: {bi_result}\")\n",
        "\n",
        "# Show which features are active\n",
        "print(f\"\\nActive unigrams in '{target_word}':\")\n",
        "for i, count in enumerate(uni_result):\n",
        "    if count > 0:\n",
        "        print(f\"  '{unigram_features[i]}': {int(count)} times\")\n",
        "\n",
        "print(f\"\\nActive bigrams in '{target_word}' (with boundaries):\")\n",
        "word_with_boundaries = '#' + target_word + '#'\n",
        "for i, count in enumerate(bi_result):\n",
        "    if count > 0:\n",
        "        print(f\"  '{bigram_features[i]}': {int(count)} times\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRANWc9Uk6pg"
      },
      "outputs": [],
      "source": [
        "twentyfour_thousand_words = twentyfour_thousand['Word'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYVQwP4OjjPC",
        "outputId": "e08c2f59-e214-486a-c0ed-3179e4bcec9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished encoding Dutch words and pseudowords.\n"
          ]
        }
      ],
      "source": [
        "# Encode all words and store results\n",
        "uni_vectors_twentyfour_thousand = {}\n",
        "bi_vectors_twentyfour_thousand = {}\n",
        "\n",
        "for word in twentyfour_thousand_words:\n",
        "    uni_vector, bi_vector = encode_ngrams(word, unigram_features, bigram_features)\n",
        "    uni_vectors_twentyfour_thousand[word] = uni_vector\n",
        "    bi_vectors_twentyfour_thousand[word] = bi_vector\n",
        "\n",
        "# Encode all words and store results\n",
        "uni_vectors_pseudowords = {}\n",
        "bi_vectors_pseudowords = {}\n",
        "\n",
        "for word in pseudoword_complete:\n",
        "    uni_vector, bi_vector = encode_ngrams(word, unigram_features, bigram_features)\n",
        "    uni_vectors_pseudowords[word] = uni_vector\n",
        "    bi_vectors_pseudowords[word] = bi_vector\n",
        "\n",
        "print(\"Finished encoding Dutch words and pseudowords.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "-w9-ySEuPp1Y",
        "outputId": "9806832d-3915-446c-ab01-995e1f310196"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "# use word valence estimates from Speed and Brysbaert (2024) to train\n",
        "# - a uni-gram model\n",
        "# - a bi-gram model\n",
        "# 2 points for correctly trained models\n",
        "\n",
        "\n",
        "twentyfour_thousand_valence = twentyfour_thousand['Valence']\n",
        "\n",
        "# Uni-gram training data\n",
        "X_uni = np.array([uni_vectors_twentyfour_thousand[word] for word in twentyfour_thousand_words])\n",
        "y = np.array(twentyfour_thousand_valence)\n",
        "\n",
        "# Train uni-gram model\n",
        "uni_model = LinearRegression()\n",
        "uni_model.fit(X_uni, y)\n",
        "\n",
        "# Bi-gram training data\n",
        "X_bi = np.array([bi_vectors_twentyfour_thousand[word] for word in twentyfour_thousand_words])\n",
        "\n",
        "# Train bi-gram model\n",
        "bi_model = LinearRegression()\n",
        "bi_model.fit(X_bi, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6RG3aeRSPtLX"
      },
      "outputs": [],
      "source": [
        "# apply trained models to predict the valence of pseudowords from Gatti et al (2024).\n",
        "# Then apply the same models back onto the training set to see how well they predict the valence of words in Speed and Brysbaert (2024).\n",
        "# 2 points for correctly applied models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bHpsjITBYmAE",
        "outputId": "2c4b22f9-a5f5-442a-c5fc-bc1e8371987f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pseudo_results\",\n  \"rows\": 1499,\n  \"fields\": [\n    {\n      \"column\": \"pseudoword\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1499,\n        \"samples\": [\n          \"slifting\",\n          \"wava\",\n          \"exgise\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_valence_uni\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06975205706389888,\n        \"min\": 2.6660969430199333,\n        \"max\": 3.138794353011123,\n        \"num_unique_values\": 1484,\n        \"samples\": [\n          3.0036721617457025,\n          3.0000586007200436,\n          2.9031219959578416\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_valence_bi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.39375887617598143,\n        \"min\": 0.6680210429578124,\n        \"max\": 5.119586014907306,\n        \"num_unique_values\": 1499,\n        \"samples\": [\n          2.6472148003172995,\n          3.028215887489499,\n          3.3403030135651504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "pseudo_results"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e280b5c8-21b4-49a6-b2ee-ef5075c19545\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pseudoword</th>\n",
              "      <th>predicted_valence_uni</th>\n",
              "      <th>predicted_valence_bi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abhert</td>\n",
              "      <td>2.919647</td>\n",
              "      <td>3.325024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abhict</td>\n",
              "      <td>2.932709</td>\n",
              "      <td>3.132259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>acleat</td>\n",
              "      <td>3.001939</td>\n",
              "      <td>3.247477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>acmure</td>\n",
              "      <td>2.991462</td>\n",
              "      <td>3.151264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>acoed</td>\n",
              "      <td>2.983596</td>\n",
              "      <td>3.112954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e280b5c8-21b4-49a6-b2ee-ef5075c19545')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e280b5c8-21b4-49a6-b2ee-ef5075c19545 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e280b5c8-21b4-49a6-b2ee-ef5075c19545');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-24ee20e7-9ceb-477a-87c9-337cf65a8ba6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24ee20e7-9ceb-477a-87c9-337cf65a8ba6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-24ee20e7-9ceb-477a-87c9-337cf65a8ba6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  pseudoword  predicted_valence_uni  predicted_valence_bi\n",
              "0     abhert               2.919647              3.325024\n",
              "1     abhict               2.932709              3.132259\n",
              "2     acleat               3.001939              3.247477\n",
              "3     acmure               2.991462              3.151264\n",
              "4      acoed               2.983596              3.112954"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "pseudowords = list(uni_vectors_pseudowords.keys())\n",
        "X_pseudo_uni = np.array([uni_vectors_pseudowords[pw] for pw in pseudowords])\n",
        "X_pseudo_bi = np.array([bi_vectors_pseudowords[pw] for pw in pseudowords])\n",
        "\n",
        "# Predict using uni-gram and bi-gram models\n",
        "pseudo_pred_uni = uni_model.predict(X_pseudo_uni)\n",
        "pseudo_pred_bi = bi_model.predict(X_pseudo_bi)\n",
        "\n",
        "# Create DataFrame for pseudoword predictions\n",
        "pseudo_results = pd.DataFrame({\n",
        "    'pseudoword': pseudowords,\n",
        "    'predicted_valence_uni': pseudo_pred_uni,\n",
        "    'predicted_valence_bi': pseudo_pred_bi,\n",
        "})\n",
        "\n",
        "pseudo_results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n4oALODuat6x",
        "outputId": "4d956e7d-07c0-4065-cb42-d3d79c4393d9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"TFT_results\",\n  \"rows\": 23986,\n  \"fields\": [\n    {\n      \"column\": \"dutch word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23986,\n        \"samples\": [\n          \"gelovig\",\n          \"deskundig\",\n          \"conditie\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_valence_uni\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06234384559257954,\n        \"min\": 2.473684210526315,\n        \"max\": 3.5557440215258866,\n        \"num_unique_values\": 23258,\n        \"samples\": [\n          2.819691581562754,\n          2.94419560071659,\n          2.8375816433764416\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_valence_bi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22199624628794531,\n        \"min\": 1.0453531361588415,\n        \"max\": 4.599999999999994,\n        \"num_unique_values\": 23985,\n        \"samples\": [\n          2.9746489181250424,\n          3.1319133793388505,\n          2.883214246727966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actual_valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6390294491544305,\n        \"min\": 1.0,\n        \"max\": 4.85,\n        \"num_unique_values\": 354,\n        \"samples\": [\n          2.411764705882353,\n          2.45,\n          2.2666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "TFT_results"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d9f92547-e36f-4a00-a159-698593ae02c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dutch word</th>\n",
              "      <th>predicted_valence_uni</th>\n",
              "      <th>predicted_valence_bi</th>\n",
              "      <th>actual_valence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mama</td>\n",
              "      <td>2.973566</td>\n",
              "      <td>3.154043</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ja</td>\n",
              "      <td>3.048731</td>\n",
              "      <td>3.020741</td>\n",
              "      <td>3.894737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>papa</td>\n",
              "      <td>2.996438</td>\n",
              "      <td>3.214637</td>\n",
              "      <td>3.722222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nee</td>\n",
              "      <td>2.989986</td>\n",
              "      <td>2.865388</td>\n",
              "      <td>2.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kaka</td>\n",
              "      <td>2.888163</td>\n",
              "      <td>2.985265</td>\n",
              "      <td>2.050000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9f92547-e36f-4a00-a159-698593ae02c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9f92547-e36f-4a00-a159-698593ae02c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9f92547-e36f-4a00-a159-698593ae02c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f7b1c694-905f-4f8a-93e8-b2b1aaea111a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7b1c694-905f-4f8a-93e8-b2b1aaea111a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f7b1c694-905f-4f8a-93e8-b2b1aaea111a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  dutch word  predicted_valence_uni  predicted_valence_bi  actual_valence\n",
              "0       mama               2.973566              3.154043        4.000000\n",
              "1         ja               3.048731              3.020741        3.894737\n",
              "2       papa               2.996438              3.214637        3.722222\n",
              "3        nee               2.989986              2.865388        2.350000\n",
              "4       kaka               2.888163              2.985265        2.050000"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Predict valence for dutch words\n",
        "X_TFT_uni = np.array([uni_vectors_twentyfour_thousand[pw] for pw in twentyfour_thousand_words])\n",
        "X_TFT_bi = np.array([bi_vectors_twentyfour_thousand[pw] for pw in twentyfour_thousand_words])\n",
        "\n",
        "# Predict using uni-gram and bi-gram models\n",
        "TFT_pred_uni = uni_model.predict(X_TFT_uni)\n",
        "TFT_pred_bi = bi_model.predict(X_TFT_bi)\n",
        "\n",
        "# Create DataFrame for pseudoword predictions\n",
        "TFT_results = pd.DataFrame({\n",
        "    'dutch word': twentyfour_thousand_words,\n",
        "    'predicted_valence_uni': TFT_pred_uni,\n",
        "    'predicted_valence_bi': TFT_pred_bi,\n",
        "    'actual_valence': twentyfour_thousand_valence\n",
        "})\n",
        "\n",
        "TFT_results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a2vLQnXBBY-",
        "outputId": "7cf7a968-7656-4f30-9736-35a980302a45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman correlation (Dutch words) — Uni-gram: 0.090\n",
            "Spearman correlation (Dutch words) — Bi-gram: 0.328\n",
            "Spearman correlation (Pseudowords) — Uni-gram: 0.327\n",
            "Spearman correlation (Pseudowords) — Bi-gram: 0.341\n"
          ]
        }
      ],
      "source": [
        "# compute the Spearman correlation coefficients between true valence and predicted valence under both uni- and bi-gram models for\n",
        "# - words from Speed and Brysbaert (2024)\n",
        "# - pseudowords from Gatti and colleagues (2024)\n",
        "# Then show both correlation coefficients.\n",
        "# 2 points for the correct Spearman correlation coefficients (rounded to the third decimal place)\n",
        "from scipy.stats import spearmanr\n",
        "# Spearman correlation\n",
        "rho_uni_dutch, _ = spearmanr(twentyfour_thousand_valence, TFT_pred_uni)\n",
        "rho_bi_dutch, _ = spearmanr(twentyfour_thousand_valence, TFT_pred_bi)\n",
        "\n",
        "print(f\"Spearman correlation (Dutch words) — Uni-gram: {rho_uni_dutch:.3f}\")\n",
        "print(f\"Spearman correlation (Dutch words) — Bi-gram: {rho_bi_dutch:.3f}\")\n",
        "\n",
        "# need correlation for pseudowords as well, however, no clear true valence so predicted_valence original dataset used\n",
        "rho_uni_pseudo, _ = spearmanr(true_valence_pseudo_word, pseudo_pred_uni)\n",
        "rho_bi_pseudo, _ = spearmanr(true_valence_pseudo_word, pseudo_pred_bi)\n",
        "\n",
        "print(f\"Spearman correlation (Pseudowords) — Uni-gram: {rho_uni_pseudo:.3f}\")\n",
        "print(f\"Spearman correlation (Pseudowords) — Bi-gram: {rho_bi_pseudo:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0P1rNg5QoDn"
      },
      "source": [
        "**Task 2** (*8 points available, see breakdown below*)\n",
        "\n",
        "Again following Gatti and colleagues, you should encode the target strings (pseudowords and Dutch words from Speed and Brysbaert) as fastText embeddings, train a multiple regression model on Dutch words and apply it to the pseudowords in Gatti et al. You should finally report the Spearman correlation coefficient between observed and predicted valence for both words and pseudowords.\n",
        "\n",
        "You should use the pre-trained fastText model for Dutch, available at this page: https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "\n",
        "Finally, you should answer two questions about the fastText model (see below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcn3PMH2cfFP",
        "outputId": "1e7d872b-5bb5-41a4-90b2-f8b28cc4f192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSkTFg15mKCG",
        "outputId": "457bcbaa-6039-4b8a-f81a-a51ac7649d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.nl.300.bin.gz\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import fasttext.util\n",
        "\n",
        "fasttext.util.download_model('nl', if_exists='ignore')\n",
        "\n",
        "ft = fasttext.load_model('cc.nl.300.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUD0VUJeRhr3"
      },
      "source": [
        "What is the dimensionality of the pre-trained Dutch fastText embeddings? (*1 point for the correct answer*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPLgwt3sjJyy",
        "outputId": "c0dcf3ff-9273-450e-a9eb-962159c6b4cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dimensionality of the pre-trained Dutch fastText embeddings is 300.\n"
          ]
        }
      ],
      "source": [
        "embedding_dimension = ft.get_dimension()\n",
        "print(f\"The dimensionality of the pre-trained Dutch fastText embeddings is {embedding_dimension}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmBdGV92eth6",
        "outputId": "67fd213a-2f10-4af5-874c-ca9903e2ccb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dutch words embeddings shape:  (23986, 300)\n",
            "Pseudowords embeddings shape:  (1499, 300)\n",
            "Embedding of 'speelplaats': [ 0.0253247  -0.00634261  0.02746305 -0.04024595  0.04888906  0.00660965\n",
            " -0.04152017 -0.01824508 -0.00645641  0.00093806  0.0708492  -0.03291791\n",
            "  0.00263817 -0.02825846 -0.02188046 -0.03188037 -0.01846142 -0.02203094\n",
            " -0.01883078 -0.00259199]\n",
            "Embedding of 'danchunk': [-0.00592199  0.00097547  0.05925412  0.00053251 -0.00386978 -0.02089076\n",
            " -0.02829577  0.00972911 -0.02510111 -0.11454885 -0.02695064  0.01551034\n",
            "  0.02384409  0.01009528  0.04545438  0.00997385 -0.00474529  0.02524533\n",
            "  0.02430548 -0.02851078]\n",
            "Subwords of 'speelplaats': ['speelplaats', '<spee', 'speel', 'peelp', 'eelpl', 'elpla', 'lplaa', 'plaat', 'laats', 'aats>']\n"
          ]
        }
      ],
      "source": [
        "def encode_corpus_fasttext(corpus, ft_model, mapping=None):\n",
        "    # if no mapping is provided, then use all dimensions of the model\n",
        "    if mapping is None:\n",
        "        dim = ft_model.get_dimension()\n",
        "        mapping = list(range(dim))\n",
        "\n",
        "    # create a feature matrix of the appropriate dimensionality\n",
        "    X = np.zeros((len(corpus), len(mapping)))\n",
        "\n",
        "    for i, instance in enumerate(corpus):\n",
        "        vec = ft_model.get_word_vector(instance)\n",
        "        X[i] = vec\n",
        "    return X, mapping\n",
        "\n",
        "\n",
        "# Encoding Dutch words and pseudowords as fastText embeddings\n",
        "\n",
        "# Real Dutch words from Speed & Brysbaert\n",
        "dutch_words = twentyfour_thousand['Word'].tolist()\n",
        "ft_dutch_words, _ = encode_corpus_fasttext(dutch_words, ft)\n",
        "\n",
        "# Pseudowords filtered from Gatti et al. set\n",
        "pseudowords = pseudoword_complete  # this is are the already filtered list\n",
        "ft_pseudowords, _ = encode_corpus_fasttext(pseudowords, ft)\n",
        "\n",
        "print(\"Dutch words embeddings shape: \", ft_dutch_words.shape)\n",
        "print(\"Pseudowords embeddings shape: \", ft_pseudowords.shape)\n",
        "\n",
        "print(\"Embedding of 'speelplaats':\", ft.get_word_vector('speelplaats')[:20])\n",
        "print(\"Embedding of 'danchunk':\", ft.get_word_vector('danchunk')[:20])\n",
        "\n",
        "# Show subwords used in 'speelplaats'\n",
        "subwords, _ = ft.get_subwords('speelplaats')\n",
        "print(\"Subwords of 'speelplaats':\", subwords)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgej4BPNRoUE"
      },
      "source": [
        "What minimum and maximum n-gram size was specified for training this fastText model? (*1 point for the correct answer*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc3iTqHBkEci",
        "outputId": "6890683d-fdaf-445c-c617-6b6f5f5570ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The minimum n-gram size is 5, and the maximum is 5.\n"
          ]
        }
      ],
      "source": [
        "long_word = next(word for word in ft.words if len(word) >= 10 and word.isalpha())\n",
        "\n",
        "# Get subwords from FastText\n",
        "subwords, _ = ft.get_subwords(long_word)\n",
        "\n",
        "# Keep only clean subwords\n",
        "clean_subwords = [s for s in subwords if s.isalpha() and s != long_word]\n",
        "subword_lengths = [len(s) for s in clean_subwords]\n",
        "\n",
        "print(f\"The minimum n-gram size is {min(subword_lengths)}, and the maximum is {max(subword_lengths)}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO8Xq-xDrRQ3"
      },
      "source": [
        "Using FastText's build_in functions instead of multiple loops.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj-cE1iipfkF",
        "outputId": "51f9e783-6bb0-4d11-a319-01ec0852e2fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min n-gram size: 5\n",
            "Max n-gram size: 5\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get min and max n-gram sizes\n",
        "min_n = ft.f.getArgs().minn\n",
        "max_n = ft.f.getArgs().maxn\n",
        "\n",
        "print(f\"Min n-gram size: {min_n}\")\n",
        "print(f\"Max n-gram size: {max_n}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW-XEksGR28U",
        "outputId": "7d795350-67ac-47aa-b7f6-ed6aada9fef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.0253247  -0.00634261  0.02746305 -0.04024595  0.04888906  0.00660965\n",
            " -0.04152017 -0.01824508 -0.00645641  0.00093806  0.0708492  -0.03291791\n",
            "  0.00263817 -0.02825846 -0.02188046 -0.03188037 -0.01846142 -0.02203094\n",
            " -0.01883078 -0.00259199]\n",
            "[-0.00592199  0.00097547  0.05925412  0.00053251 -0.00386978 -0.02089076\n",
            " -0.02829577  0.00972911 -0.02510111 -0.11454885 -0.02695064  0.01551034\n",
            "  0.02384409  0.01009528  0.04545438  0.00997385 -0.00474529  0.02524533\n",
            "  0.02430548 -0.02851078]\n"
          ]
        }
      ],
      "source": [
        "# encode Dutch words and pseudowords as fastText embeddings\n",
        "# show the first 20 values of the embedding of the word 'speelplaats' and of the pseudoword 'danchunk'\n",
        "# 2 points for correctly encoding words and pseudowords with fastText\n",
        "\n",
        "embedding_real = ft.get_word_vector('speelplaats')\n",
        "embedding_fake = ft.get_word_vector('danchunk')\n",
        "\n",
        "print(embedding_real[:20])\n",
        "print(embedding_fake[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74IxcEHG_Jov",
        "outputId": "e98cc166-ebaf-4216-a8e7-395e2bea4fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding for 'speelplaats' (first 20 values): [ 0.0253247  -0.00634261  0.02746305 -0.04024595  0.04888906  0.00660965\n",
            " -0.04152017 -0.01824508 -0.00645641  0.00093806  0.0708492  -0.03291791\n",
            "  0.00263817 -0.02825846 -0.02188046 -0.03188037 -0.01846142 -0.02203094\n",
            " -0.01883078 -0.00259199]\n",
            "Embedding for 'danchunk' (first 20 values): [-0.00592199  0.00097547  0.05925412  0.00053251 -0.00386978 -0.02089076\n",
            " -0.02829577  0.00972911 -0.02510111 -0.11454885 -0.02695064  0.01551034\n",
            "  0.02384409  0.01009528  0.04545438  0.00997385 -0.00474529  0.02524533\n",
            "  0.02430548 -0.02851078]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dutch_embeddings_dict = {}\n",
        "pseudo_embeddings_dict = {}\n",
        "\n",
        "# Loop over the list of words/pseudowords\n",
        "for word in twentyfour_thousand_words:\n",
        "    embedding = ft.get_word_vector(word)\n",
        "    dutch_embeddings_dict[word] = embedding\n",
        "\n",
        "# Loop over the list of words/pseudowords\n",
        "for word in pseudowords:\n",
        "    embedding = ft.get_word_vector(word)\n",
        "    pseudo_embeddings_dict[word] = embedding\n",
        "# Print the first 20 values of the embeddings for 'speelplaats' and 'danchunk'\n",
        "print(\"Embedding for 'speelplaats' (first 20 values):\", dutch_embeddings_dict['speelplaats'][:20])\n",
        "print(\"Embedding for 'danchunk' (first 20 values):\", pseudo_embeddings_dict['danchunk'][:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "3ePBth7cSAJU",
        "outputId": "496362c3-2be7-43b6-8112-02a050ce73c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train regression model on word valence\n",
        "# 1 point for correctly training the regression model\n",
        "\n",
        "X_dutch_embedding = np.array([dutch_embeddings_dict[word] for word in twentyfour_thousand_words])\n",
        "y_dutch_embedding = np.array(twentyfour_thousand_valence)\n",
        "embed_model = LinearRegression()\n",
        "embed_model.fit(X_dutch_embedding, y_dutch_embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REJnnM2mSHHK"
      },
      "outputs": [],
      "source": [
        "# apply the trained model to predict the valence of pseudowords from Gatti et al (2024).\n",
        "# Then apply the same model back onto the training set to see how well it predicts the valence of words in Speed and Brysbaert (2024).\n",
        "# 1 point for correctly applied model\n",
        "\n",
        "X_pseudo_embedding = np.array([pseudo_embeddings_dict[pw] for pw in pseudowords])\n",
        "prediction_pseudo_words = embed_model.predict(X_pseudo_embedding )\n",
        "prediction_dutch_words = embed_model.predict(X_dutch_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIyyTyfHSKh5",
        "outputId": "0c6f5f7e-0c6d-4fe5-bd27-9cdfc2bd5a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman correlation (Dutch words) — embedding model: 0.724\n",
            "Spearman correlation (Pseudo words) — embedding model: 0.176\n"
          ]
        }
      ],
      "source": [
        "# compute the Spearman correlation coefficients between true valence and predicted valence for\n",
        "# - words from Speed and Brysbaert (2024)\n",
        "# - pseudowords from Gatti and colleagues (2024)\n",
        "# Then show the correlation coefficient.\n",
        "# 1 point for the correct Spearman correlation coefficients (rounded to the third decimal place)\n",
        "\n",
        "# Spearman correlation\n",
        "rho_dutch_embedding, _ = spearmanr(twentyfour_thousand_valence, prediction_dutch_words)\n",
        "rho_pseudo_embedding, _ = spearmanr(true_valence_pseudo_word, prediction_pseudo_words)\n",
        "\n",
        "print(f\"Spearman correlation (Dutch words) — embedding model: {rho_dutch_embedding:.3f}\")\n",
        "print(f\"Spearman correlation (Pseudo words) — embedding model: {rho_pseudo_embedding:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnqKJ5XOSTbM"
      },
      "source": [
        "**Task 3** (*6 points available, see breakdown below*)\n",
        "\n",
        "Now you are asked to extend the work by Gatti et al by also considering the representations learned by a transformer-based models, in detail *RobBERT v2* (https://huggingface.co/pdelobelle/robbert-v2-dutch-base). You should follow the same pipeline as for the previous models, encoding both Dutch words from Speed and Brysbaert (2024) and the pseudowords from Gatti et al using the embedding of each string at layer 0, before positional information is factored in. If a string consists of multiple tokens, average the embeddings of all tokens to produce the embedding of the whole string. Then train a multiple regression model on the valence of Dutch words, apply it to the pseudowords, and compute the Spearman correlation between observed and predicted ratings.\n",
        "\n",
        "Use the HuggingFace model card for RobBERT v2 to check how to access it.\n",
        "\n",
        "I recommend saving the embeddings to file once you have generated them and you know they are correct: embedding thousands of strings takes some time, and you don't want to have to do it again. For the same reason, develop your code by considering only a small fractions of the words and pseudowords, in order to quickly see if something is wrong. Only when you are positive it works, embed all strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ppi-Zcp6i9Rn",
        "outputId": "44db8efe-8703-4716-d361-76f184d3bfe8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/merges.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/tokenizer_config.json\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/tokenizer.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 40000\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.52.4\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 40000\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/model.safetensors\n",
            "Some weights of the model checkpoint at pdelobelle/robbert-v2-dutch-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# load and instantiate the right model\n",
        "# 1 point for loading the right model\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm12jhIjlp0j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB4LmuRuoe8A"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def chunks(lst, n):\n",
        "    \"\"\"Chunks a list into equal chunks containing n elements. Returns a list of lists.\"\"\"\n",
        "    return [lst[i:i + n] for i in range(0, len(lst), n)]\n",
        "\n",
        "def get_embeddings(words):\n",
        "    inputs = tokenizer(words, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "\n",
        "    token_embeddings = outputs.hidden_states[0]  # shape: (batch_size, seq_len, hidden_size)\n",
        "    attention_mask = inputs['attention_mask'].unsqueeze(-1)\n",
        "\n",
        "    # Average token embeddings across non-padding tokens\n",
        "    summed = (token_embeddings * attention_mask).sum(1)\n",
        "    counts = attention_mask.sum(1)\n",
        "    avg_embeddings = (summed / counts).cpu().numpy()\n",
        "\n",
        "    return avg_embeddings\n",
        "\n",
        "# Encode in batches\n",
        "batch_size = 32\n",
        "realword_chunks = chunks(twentyfour_thousand_words, batch_size)\n",
        "pseudoword_chunks = chunks(pseudoword_complete, batch_size)\n",
        "\n",
        "realword_embeddings = []\n",
        "pseudoword_embeddings = []\n",
        "\n",
        "for chunk in realword_chunks:\n",
        "    realword_embeddings.extend(get_embeddings(chunk))\n",
        "\n",
        "for chunk in pseudoword_chunks:\n",
        "    pseudoword_embeddings.extend(get_embeddings(chunk))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4HRQ5dxp0mQ",
        "outputId": "213b186e-c3c7-4189-aae3-0883a48b5545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Real word embeddings shape: (23986, 768)\n",
            "Pseudoword embeddings shape: (1499, 768)\n",
            "\n",
            "First 20 values for 'mama':\n",
            "[ 0.10573046 -0.13243617  0.02660742 -0.16841179 -0.27212244  0.22280149\n",
            "  0.34766036  0.1087931   0.18475425 -0.15579909 -0.16617611  0.39199668\n",
            "  0.14786334  0.31454724 -0.08547205  0.09090855  0.2049371   0.33787522\n",
            " -0.08932306 -0.07955239]\n",
            "\n",
            "First 20 values for 'abhert':\n",
            "[-0.12733552 -0.12629339  0.19149742 -0.11284536 -0.15879726  0.19802031\n",
            " -0.13981844  0.39876682 -0.27620262  0.26281267  0.16537903  0.29070553\n",
            "  0.01715505  0.4492181  -0.06860778  0.26204032  0.1455008   0.24524692\n",
            " -0.26653197  0.02474991]\n"
          ]
        }
      ],
      "source": [
        "# Check shapes\n",
        "print(\"Real word embeddings shape:\", np.array(realword_embeddings).shape)\n",
        "print(\"Pseudoword embeddings shape:\", np.array(pseudoword_embeddings).shape)\n",
        "\n",
        "# Print first 20 embedding values for example words\n",
        "sample_real_word = twentyfour_thousand_words[0]\n",
        "sample_pseudoword = pseudoword_complete[0]\n",
        "\n",
        "print(f\"\\nFirst 20 values for '{sample_real_word}':\")\n",
        "print(realword_embeddings[0][:20])\n",
        "\n",
        "print(f\"\\nFirst 20 values for '{sample_pseudoword}':\")\n",
        "print(pseudoword_embeddings[0][:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tcbZIaTquoz",
        "outputId": "f1a67089-d993-4e90-ee27-20d2d2d5e895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'miauwen' found at index 274\n",
            "First 20 embedding values for 'miauwen':\n",
            "[-0.10084925 -0.21053834 -0.04177775 -0.08898214 -0.23452406  0.45046386\n",
            "  0.40555865 -0.174505    0.3688112   0.06516795  0.13631444 -0.10772562\n",
            "  0.11235957  0.12476961 -0.23446035  0.4449307   0.14150427 -0.07074475\n",
            " -0.14118971 -0.1270578 ]\n",
            "\n",
            "'lixthless' found at index 694\n",
            "First 20 embedding values for 'lixthless':\n",
            "[-0.20995182  0.34993732 -0.17283982  0.08660037 -0.24632312  0.32064924\n",
            "  0.252103   -0.02056611 -0.00912013  0.15606797  0.08206394  0.16542049\n",
            " -0.3391408   0.48972556 -0.25270566  0.06884155  0.4151193  -0.08710929\n",
            "  0.0304805  -0.21037637]\n"
          ]
        }
      ],
      "source": [
        "# Check and print 'miauwen'\n",
        "if 'miauwen' in twentyfour_thousand_words:\n",
        "    index_miauwen = twentyfour_thousand_words.index('miauwen')\n",
        "    embedding_miauwen = realword_embeddings[index_miauwen]\n",
        "    print(f\"'miauwen' found at index {index_miauwen}\")\n",
        "    print(\"First 20 embedding values for 'miauwen':\")\n",
        "    print(embedding_miauwen[:20])\n",
        "else:\n",
        "    print(\"'miauwen' not found in real word list.\")\n",
        "\n",
        "# Check and print 'lixthless'\n",
        "if 'lixthless' in pseudoword_complete:\n",
        "    index_lixthless = pseudoword_complete.index('lixthless')\n",
        "    embedding_lixthless = pseudoword_embeddings[index_lixthless]\n",
        "    print(f\"\\n'lixthless' found at index {index_lixthless}\")\n",
        "    print(\"First 20 embedding values for 'lixthless':\")\n",
        "    print(embedding_lixthless[:20])\n",
        "else:\n",
        "    print(\"'lixthless' not found in pseudoword list.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "BFq3hHCDUPjL",
        "outputId": "e8d43693-6c01-49e3-b9de-46b6adc4b1d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-5 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-5 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-5 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-5 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-5 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-5 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-5 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-5 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train regression model on word valence estimates from Speed and Brysbaert (2024)\n",
        "# 1 point for correctly training the regression model\n",
        "\n",
        "X_train = realword_embeddings\n",
        "y_train = twentyfour_thousand[\"Valence\"].tolist()\n",
        "\n",
        "lm = LinearRegression()\n",
        "lm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaU9NAxUSoW"
      },
      "outputs": [],
      "source": [
        "# apply the trained model to predict the valence of pseudowords from Gatti et al (2024).\n",
        "# Then apply the same model back onto the training set to see how well it predicts the valence of words in Speed and Brysbaert (2024).\n",
        "# 1 point for correctly applied model\n",
        "\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Applying trained model to pseudowords\n",
        "X_test = pseudoword_embeddings\n",
        "y_test = true_valence_pseudo_word\n",
        "\n",
        "y_pred = lm.predict(X_test)  # predicted valence for pseudowords\n",
        "y_pred_train = lm.predict(X_train)  # predicted valence for real words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVcuHS02UUPd",
        "outputId": "fbc2e16c-5106-416a-d64c-a8eadfdd68b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman correlation for real words (training set): 0.518\n",
            "Spearman correlation for pseudowords: 0.185\n"
          ]
        }
      ],
      "source": [
        "# compute the Spearman correlation coefficients between true valence and predicted valence for\n",
        "# - words from Speed and Brysbaert (2024)\n",
        "# - pseudowords from Gatti and colleagues (2024)\n",
        "# show the correlation coefficient.\n",
        "# 1 point for the correct Spearman correlation coefficients (rounded to the third decimal place)\n",
        "\n",
        "# Spearman correlation\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "corr_real, _ = spearmanr(y_train, y_pred_train)\n",
        "print(\"Spearman correlation for real words (training set): {:.3f}\".format(corr_real))\n",
        "\n",
        "corr_pseudo, _ = spearmanr(y_test, y_pred)\n",
        "print(\"Spearman correlation for pseudowords: {:.3f}\".format(corr_pseudo))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vpVgM_I68mG"
      },
      "source": [
        "hope it works now\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfWX1QTfB172"
      },
      "source": [
        "**Task 4** (*16 points available, 4 for each question*)\n",
        "\n",
        "Answer the following questions.\n",
        "\n",
        "**4a.** Describe the performance of each featurization, comparing\n",
        "- the performance of a same model betmween the training and test set\n",
        "- the performance of different models on the training set\n",
        "- the performance of different models on the test set\n",
        "\n",
        "(*4 points available, max 150 words*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EONmoGe8CAyI"
      },
      "source": [
        "**Same model (training [Dutch words] vs. test [Pseudowords]):**\n",
        "Uni-gram performs poorly on the training set (ρ = 0.090) but improves on pseudowords (ρ = 0.327), likely due to letter-level cues matching affective proxies. Bi-gram performs moderately on Dutch (ρ = 0.328) and slightly better on pseudowords (ρ = 0.341), indicating stable but modest generalization. FastText excels on Dutch (ρ = 0.724) but drops sharply on pseudowords (ρ = 0.176), suggesting strong lexical representation but weak transfer. RobBERT also shows moderate performance on Dutch (ρ = 0.518) and declines on pseudowords (ρ = 0.184), likely due to the model's reliance on meaningful context.\n",
        "\n",
        "**Training set comparison:**\n",
        "FastText (ρ = 0.724) outperforms RobBERT (ρ = 0.518), bi-gram (ρ = 0.328), and uni-gram (ρ = 0.090), highlighting the advantage of rich subword embeddings for real-word valence prediction.\n",
        "\n",
        "Test set comparison:\n",
        "Bi-gram (ρ = 0.341) leads slightly, followed by uni-gram (ρ = 0.327), RobBERT (ρ = 0.184), and FastText (ρ = 0.176), suggesting simpler models better align with pseudoword surface patterns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpkgvOqeB6jH"
      },
      "source": [
        "**4b.** Compare the correlations you found when training uni-gram, bi-gram, and fastText models on Dutch words and the correlations of similar models trained on English data as reported by Gatti and colleagues; summarize the most important similarities and differences.\n",
        "\n",
        "(*4 points available, max 150 words*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv7P2zvnCBiX"
      },
      "source": [
        "In our Dutch data, uni-gram and bi-gram models achieved modest valence correlations on real words (ρ = 0.090 and ρ = 0.328), closely matching Gatti et al.’s English-trained letter (ρ = 0.11) and bigram (ρ = 0.33) models. FastText, however, achieved a high correlation in both studies (ρ = 0.724 for Dutch; ρ = 0.79 for English), confirming its strong semantic generalization across languages. A key difference is that in our Dutch results, bigrams outperformed unigrams, while Gatti et al found the opposite: in pseudowords, English letter-based models outperformed bigrams and embeddings. Additionally, Gatti's best-performing pseudoword model was letter-only, whereas our Dutch test set (pseudowords) favored bigram models (ρ = 0.341) slightly over unigrams (ρ = 0.327), suggesting that Dutch speakers may rely more on subword co-occurrence patterns. Overall, the studies agree that surface-form cues matter more than semantic ones in pseudoword valence, but the specific form-based predictors may vary across languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ2SxrYHy3Hx"
      },
      "source": [
        "**4c.** Do you think the performance of the fastText featurization would change if you were to use different n-grams? Would you make them smaller or larger? Justify your answer.\n",
        "\n",
        "(*4 points available, max 150 words*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M-lvw2qVjNH"
      },
      "source": [
        "The performance of the FastText featurization could change with different n-gram sizes, as n-grams capture varying levels of contextual and subword information. Smaller n-grams focus on finer-grained subword patterns, potentially improving performance for short words or pseudowords with subtle letter-based variations, but they may miss broader contextual patterns. Larger n-grams capture more context, which could benefit longer words or those with complex morphological structures, but they risk overfitting or generating sparse representations for rare patterns.\n",
        "For this task, given our findings that fastText underperformed on pseudowords (ρ = 0.176), slightly shortening the n-grams might improve performance by increasing overlap with subword patterns common in pseudowords. This is supported by Gatti et al.’s supplementary results, where altering n-gram lengths had a measurable (though limited) effect on prediction quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_-zN3Vp2OBD"
      },
      "source": [
        "**4d.** Do you think that training the same models on uni-grams, bi-grams, fastText and transformer-based embeddings but using valence ratings for Finnish (a language which uses the same alphabet as English but is not a IndoEuropean language) words would yield a similar pattern of results? Justify your answer.\n",
        "\n",
        "(*4 points available, max 150 words*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20T-4kCdVppE"
      },
      "source": [
        "Training models on uni-grams, bi-grams, fastText, and transformer-based embeddings with Finnish valence ratings is unlikely to replicate the Dutch results. Furthermore, morphologically speaking, Finnish vasty differs from Dutch despite both using the 'English' alphabet. Finnish’s complex, longer words may weaken uni- and bi-gram models, as they struggle to capture multi-morphemic structures, likely yielding lower correlations than Dutch. FastText, using subword embeddings, should perform better, but optimal n-gram sizes may differ, potentially altering its 0.724 correlation. Transformer-based embeddings (e.g., Finnish BERT) could outperform others by modeling contextual nuances, but success depends on robust pretraining. Cultural differences in valence perception may further diverge results. While fastText and transformers may remain strong, the pattern of correlations will likely differ due to linguistic and cultural factors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4ILTPziXptK"
      },
      "source": [
        "**Task 5** (*3 points available*)\n",
        "\n",
        "Compute the average Levenshtein Distance (aLD) between each pseudoword and the 20 words at the smallest edit distance from it. Consider the set of words you used to filter out pseudowords that happen to be valid Dutch words (the file is available in this OSF repository: https://osf.io/9zymw/) to retrieve the 20 words at the smallest edit distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGks7N-JCjFu",
        "outputId": "ec757841-c418-4c48-bfc9-2b1668378ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.27.1 rapidfuzz-3.13.0\n"
          ]
        }
      ],
      "source": [
        "# compute the average Levenshtein distance from each pseudoword to the words used to filter out pseudowords.\n",
        "# Show the aLD estimate for the pseudowords 'nedukes', 'pewbin', and 'vibcines'\n",
        "# 3 points for correctly computing aLD for pseudowords\n",
        "!pip install Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnU-T1Ai0G5V",
        "outputId": "05292680-6e6b-4784-a123-7608d85b9384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Levenshtein Distance for 'nedukes': 6.800\n",
            "Average Levenshtein Distance for 'pewbin': 6.500\n",
            "Average Levenshtein Distance for 'vibcines': 7.500\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import Levenshtein\n",
        "\n",
        "# Function to compute average Levenshtein distance\n",
        "def compute_aLD(pseudoword, word_list, top_n=20):\n",
        "    distances = [(word, Levenshtein.distance(pseudoword, word)) for word in word_list]\n",
        "    distances.sort(key=lambda x: x[1])  # sort by distance\n",
        "    top_20 = distances[:top_n]\n",
        "    avg_ld = np.mean([dist for word, dist in top_20])\n",
        "    return avg_ld\n",
        "\n",
        "# aLD for all pseudowords\n",
        "ald_values = {pw: compute_aLD(pw, twentyfour_thousand) for pw in pseudoword_complete}\n",
        "\n",
        "for target in ['nedukes', 'pewbin', 'vibcines']:\n",
        "    ald = ald_values.get(target)\n",
        "    if ald is not None:\n",
        "        print(f\"Average Levenshtein Distance for '{target}': {ald:.3f}\")\n",
        "    else:\n",
        "        print(f\"'{target}' not found in pseudoword list.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBdwMhHsYY0j"
      },
      "source": [
        "**Task 6** (*3 points available*)\n",
        "\n",
        "For each pseudoword, record the number of tokens in which RobBERT v2 encodes it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDOechQfmvqE",
        "outputId": "4e2843ac-9ffd-4348-e8ae-79a6e42186f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "yuxwas: 3\n",
            "skibfy: 4\n",
            "errords: 3\n"
          ]
        }
      ],
      "source": [
        "# record the number of tokens in which RobBERT divides each pseudoword\n",
        "# show the number of tokens for the pseudowords 'yuxwas', 'skibfy', and 'errords'\n",
        "# 3 points for correctly mapping pseudowords to number of tokens\n",
        "dictionary_robbert_tokencount = {}\n",
        "for pseudoword in pseudoword_complete:\n",
        "  dictionary_robbert_tokencount[pseudoword] = len(tokenizer.tokenize(pseudoword))\n",
        "\n",
        "print(\"yuxwas:\", dictionary_robbert_tokencount[\"yuxwas\"])\n",
        "print(\"skibfy:\", dictionary_robbert_tokencount[\"skibfy\"])\n",
        "print(\"errords:\", dictionary_robbert_tokencount[\"errords\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9LxipdMYqXN"
      },
      "source": [
        "**Task 7** (*5 points available, see breakdown below*)\n",
        "\n",
        "Compute the residuals of the predicted valence under the four regressors trained and applied in tasks 1 to 3. Then, correlate the residuals from all four models with aLD. Finally, correlate the residuals from the RobBERT v2 model with the number of tokens in which each pseudoword is split. Use the Pearson's correlation coefficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc2p7UXSCi-q",
        "outputId": "d36b69ea-c01d-4029-db76-f86bf06009c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count    1499.000000\n",
            "mean        3.185445\n",
            "std         1.446554\n",
            "min        -0.417114\n",
            "25%         1.985112\n",
            "50%         3.162839\n",
            "75%         4.412358\n",
            "max         6.841151\n",
            "Name: predicted_valence, dtype: float64\n",
            "\n",
            "count    1499.000000\n",
            "mean        3.235827\n",
            "std         1.439069\n",
            "min        -0.671984\n",
            "25%         2.110548\n",
            "50%         3.188955\n",
            "75%         4.440921\n",
            "max         6.345326\n",
            "Name: predicted_valence, dtype: float64\n",
            "\n",
            "count    1499.000000\n",
            "mean        3.200384\n",
            "std         1.444841\n",
            "min        -0.675607\n",
            "25%         2.001129\n",
            "50%         3.200173\n",
            "75%         4.438290\n",
            "max         6.139644\n",
            "Name: predicted_valence, dtype: float64\n",
            "\n",
            "count    1499.000000\n",
            "mean        3.148647\n",
            "std         1.381874\n",
            "min        -0.697697\n",
            "25%         2.033229\n",
            "50%         3.137965\n",
            "75%         4.321047\n",
            "max         7.634713\n",
            "Name: predicted_valence, dtype: float64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# compute the residuals from all four regression models fitted before\n",
        "# 1 point available for correctly computing residuals\n",
        "residuals_embed = true_valence_pseudo_word - embed_model.predict(X_pseudo_embedding)\n",
        "residuals_robbert = true_valence_pseudo_word - lm.predict(X_test)\n",
        "residuals_uni = true_valence_pseudo_word - uni_model.predict(X_pseudo_uni)\n",
        "residuals_bi = true_valence_pseudo_word - bi_model.predict(X_pseudo_bi)\n",
        "\n",
        "print(residuals_embed.describe(), end=\"\\n\\n\")\n",
        "print(residuals_robbert.describe(), end=\"\\n\\n\")\n",
        "print(residuals_uni.describe(), end=\"\\n\\n\")\n",
        "print(residuals_bi.describe(), end=\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxI75VYCOGp2",
        "outputId": "4a1602bf-f26b-48b5-adfd-2860bcf9f1e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1499\n",
            "1499\n"
          ]
        }
      ],
      "source": [
        "print(len(residuals_robbert))\n",
        "print(len(ald_values.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkqJLI17C0Ml",
        "outputId": "ddb6e58b-cc11-4f81-cdb1-718fce05e125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation between embed residuals and aLD: -0.3621\n",
            "Correlation between RobBERT residuals and aLD: -0.3483\n",
            "Correlation between uni residuals and aLD: -0.3579\n",
            "Correlation between bi residuals and aLD: -0.3986\n",
            "Correlation between RobBERT residuals and number of tokens: -0.2369\n"
          ]
        }
      ],
      "source": [
        "# Pearson's correlation between residuals and average LD for all models,\n",
        "# as well as the correlation between RobBERT v2 residuals and the number of tokens in which each pseudoword\n",
        "#  is encoded by the RobBERT v2 model.\n",
        "# Finally print all correlation coefficients\n",
        "# 4 points for the correct correlation coefficients\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "import numpy as np\n",
        "\n",
        "pseudowords = list(ald_values.keys())  \n",
        "ald_list = [ald_values[p] for p in pseudowords]\n",
        "robbert_tokens_list = [dictionary_robbert_tokencount[p] for p in pseudowords]\n",
        "\n",
        "# Pearson's correlation between residuals and aLD for all models\n",
        "correlation_embed, _ = pearsonr(residuals_embed, ald_list)\n",
        "correlation_robbert, _ = pearsonr(residuals_robbert, ald_list)\n",
        "correlation_uni, _ = pearsonr(residuals_uni, ald_list)\n",
        "correlation_bi, _ = pearsonr(residuals_bi, ald_list)\n",
        "\n",
        "# Pearson's correlation between RobBERT residuals and number of tokens\n",
        "correlation_robbert_tokens, _ = pearsonr(residuals_robbert, robbert_tokens_list)\n",
        "\n",
        "print(f\"Correlation between embed residuals and aLD: {correlation_embed:.4f}\")\n",
        "print(f\"Correlation between RobBERT residuals and aLD: {correlation_robbert:.4f}\")\n",
        "print(f\"Correlation between uni residuals and aLD: {correlation_uni:.4f}\")\n",
        "print(f\"Correlation between bi residuals and aLD: {correlation_bi:.4f}\")\n",
        "print(f\"Correlation between RobBERT residuals and number of tokens: {correlation_robbert_tokens:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6owroLfAC4vf"
      },
      "source": [
        "**Task 8** What is the relation between the errors each model made and aLD? what about the number of tokens (limited to the RobBERT v2 model)?\n",
        "\n",
        "(*4 points available, max 150 words*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OQx4UyJOCs_"
      },
      "source": [
        "The negative correlations between the residuals of each model and aLD indicate that as aLD increases, meaning the pseudowords are more complex or differ more from typical words. Hnece, the models tend to make larger errors. This is because higher residuals indicate worse model performance, so the models struggle more with inputs that have higher complexity or deviation.\n",
        "\n",
        "Among the models, the bigram model shows the strongest negative correlation (-0.3986), suggesting its errors increase the most as the complexity of the pseudowords grows.\n",
        "\n",
        "For the RobBERT v2 model, the negative correlation between residuals and the number of tokens (-0.2369) means that pseudowords encoded into fewer tokens tend to have smaller errors, while those split into more tokens yield larger residuals. This suggests that more fragmented or complex tokenization corresponds to higher model errors.\n",
        "\n",
        "Overall, both higher complexity (aLD) and greater tokenization complexity are associated with increased prediction errors in the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvaOAjqxuHgm"
      },
      "source": [
        "*testo in corsivo*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
